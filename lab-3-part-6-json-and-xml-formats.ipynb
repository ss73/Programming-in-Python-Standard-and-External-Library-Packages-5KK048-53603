{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7827828,"sourceType":"datasetVersion","datasetId":4587225}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lab 3 - Part 6: Json and XML formats\n=============\nIn this lab, we will parse XML files and create json files. Three different modules from the [Python Standard Library](https://docs.python.org/3/library/index.html) will be used:\n- [ElementTree XML](https://docs.python.org/3/library/xml.etree.elementtree.html)\n- [JSON encoder and decoder](https://docs.python.org/3/library/json.html)\n- [Collections](https://docs.python.org/3/library/collections.html)\n\nWe will use a [term list](https://sprakresurser.isof.se/myndighetstermlistan/) that is developed and made available by the Institute for Language and Folklore. It is in XML format, more specifically a term format that is called TBX. Therefore, the file has the suffix '.tbx'.\n\nThe focus of this lab will be to practice understanding Python code that someone else has written, rather than to write that much code yourself. In step 4, 6, 10 and 11, you will change the code, however.\n\n\nI. Understand the XML parsing, create a readable json file and get to know the Counter class\n------------------------------------------------------------------------------\n1) The XML file that is being parsed is a [term list](https://sprakresurser.isof.se/myndighetstermlistan/) from the Government Authority Terminology group. Take a look at the structure of the XML file. What kind of information does it contain? **`<term>activity report</term>` is one of the XML elements in the file.** \n\n**In this element, what is the *tag*, what is the *closing tag* and what is the *text*?** \n\n> __Answer__: A tag is defined inside brackets; <a_tag>. Tags are closed with </a_tag>. Everything\n  between the opening and closing tags are children to the tag.\n\n**Can you give an example of a tag that has an *attribute*?**\n\n> __Answer__: The `termEntry` tag has the attribute `id`.\n\n**Can you give an example of an element that contains another element?**\n\n> __Answer__: The element `termEntry` with `id=\"aktivitetsrapport\"` contains several `langSet` elements\n\n**Give another example  (besides ``term``) of an element that contains *text*?**\n\n> __Answer__: For example `note`\n\n2) The code below contains three different ways of importing components from the Python standard library. How does the syntax differ between the three ways they are imported? The way the components are imported affects the syntax when using the components. Spot all code lines where the imported components are used. How does the syntax differ, depending on the import statement syntax used?\n\n> __Answer__: `import x as y` is used to refer to the imported component by the alias `y`,\n  often as a means of having a shorter identifier. The second, plain variant, `import x` requires\n  explicit referencing, e.g. `x.something()`. The final variant, `from x import y` allows referencing\n  `y` as if it was declared locally\n\n3) Run and make sure you understand the code for parsing the XML below. There are many ways to parse XML files, and the code below is just an example. If there are parts of the code you don't understand, try to print the elements that are being looped over, to understand each part.\n\n4) CHANGE THE CODE: Take a look at the resulting json file (`en-term-entries.json`), for instance by downloading it and looking at it on your own computer. \n\nHow the json is formated now makes it very unitelligible. Read the [json documentation](https://docs.python.org/3/library/json.html) to see if there is a possibility to format it better, by adding an indentation. \n\n**Most lists associated with the keyword ``terms`` include one element, what are the two exceptions?**\n\n5) **What is the difference between json.dump() and json.dumps()?** Which is used here, and why? \n\n> __Answer__: dump() writes to a text stream, dumps() returns a JSON string. In this case, the first option is applied as it gets written to a file.  \n\n6) CHANGE THE CODE: There is a code line below with just an emtpy dictionary `language_dict = {}`\nInstead of this code line, write code that reads the content of the json file you have just saved.  Read the [json documentation](https://docs.python.org/3/library/json.html) to find the opposite to `json.dump()`, i.e. how to instead load the content from a file.  \n\n7) Take a look at the [Counter](https://docs.python.org/3/library/collections.html#collections.Counter) class. \nIn addtion to the Python [built-in types](https://docs.python.org/3/library/stdtypes.html), such as [lists](https://docs.python.org/3/library/stdtypes.html#sequence-types-list-tuple-range) and [dicts](https://docs.python.org/3/library/stdtypes.html#mapping-types-dict), there is also a modudule for a bit more specialised Collections. The Counter class is one such example of a more specialised Collection. To use it, you need to import it from the module. \n\n**When and for what purpose is the Counter class used in the code below?**\n\n> __Answer__: Count the number of letters in a list of strings, like a histogram\n\n8) Make sure you understand what the `count_letters_in_all_terms_and_definitions_for_lang`, `get_flattened_from_list_list` and `count_letters` functions do. If you don't understand, go through the functions step-by-step, by printing the variables.\n\n[list comprehensions](https://www.w3schools.com/python/python_lists_comprehension.asp) is again used (as in file reading/writing lab). This time, it is used together with a condition.\n\n9) What are the five most frequent letters for the english terms? (Remember it till later.)\n\n> __Answer__: e a r i t","metadata":{}},{"cell_type":"code","source":"# Import a module, and rename it to ET (a bit strange name for a module)\nimport xml.etree.ElementTree as ET\n\n# Import a module. and don't rename it\nimport json\n\n# Import a specific class from the module collections, the class Counter, \nfrom collections import Counter\n\n###########\n# Constants\n###########\n\n# Keys for the json file\nTERMS = \"terms\"\nDEFINITIONS = \"definitions\"\n\n# Language codes\nEN = \"en\"\nSV = \"sv\"\n\n############\n# Functions\n###########\n\ndef count_letters(str_list):\n    joined_str_lower = \"\".join(str_list).lower()   \n    letter_counter = Counter(list(joined_str_lower))\n    return letter_counter\n\n# Flattens one nested level of a list\ndef get_flattened_from_list_list(list_list):\n    flat_list = []\n    for lst in list_list:\n        flat_list.extend(lst)\n    return flat_list\n    \ndef count_letters_for_entry_type(terms_dict, language, entry_type):\n    # Check that there are term entries for the language\n    if language not in terms_dict:\n        print(f\"No term entries for the language: {language}. Return None\")\n        return None\n    \n    terms_entries_for_lang = terms_dict[language]\n    print(f\"\\nFound {len(terms_entries_for_lang)} term entries for the language: {language}\")\n    \n    if len(terms_entries_for_lang) > 1:\n        print(f\"\\nFirst and second term entries look like this: {terms_entries_for_lang[0:2]}\\n\")\n    \n    # Get all the terms in the term entries\n    all_terms_list_list = \\\n    [term[entry_type] for term in terms_entries_for_lang if entry_type in term]\n    \n    # all_terms_list_list will be a list of lists. \n    # But 'count_letters' takes a flat list of strings as parameter.\n    # Therefore, flatten the list\n    all_terms_list = get_flattened_from_list_list(all_terms_list_list)\n    \n    # Count all letters for the terms\n    letter_dict_terms = count_letters(all_terms_list)\n    \n    return letter_dict_terms\n\n\ndef parse_tbx_file_for_language(tbx_filename, json_output_filename, language_code):\n    # Constants to use for parsing\n    NAME_SPACE_STR = \"{http://www.w3.org/XML/1998/namespace}\"\n    LANG_ATTR = NAME_SPACE_STR + \"lang\"\n    TERM = \"term\"\n    DESCRIPTIONS = \"descrip\" # USE THIS CONSTANT FOR STEP 11\n    \n    tree = ET.parse(tbx_filename)\n    root = tree.getroot()\n    print(root)\n    \n    all_terms = []\n    for term_entry in root.iter('termEntry'):\n        term_entry_dict = {}\n        \n        for language in term_entry.iter('langSet'):\n            if language.attrib[LANG_ATTR] == language_code:\n                term_entry_dict[TERMS] = [term.text for term in language.iter(TERM)]\n                #term_entry_dict[DEFINITIONS] # ... # CHANGE CODE HERE, FOR STEP 11 IN THE INSTRUCTIONS\n                term_entry_dict[DEFINITIONS] = [desc.text for desc in language.iter(DESCRIPTIONS)]\n                \n        all_terms.append(term_entry_dict)\n   \n    language_output_dict = {language_code: all_terms}\n    \n    \n    # Save the output as a json file\n    with open(json_output_filename, \"w\") as fp:\n        json.dump(language_output_dict, fp, indent=2) # CHANGE THE CODE HERE, FOR STEP 4 in the instructions\n        #json.dump(language_output_dict, fp) \n\n######################\n# The code starts here\n########################\n\n# What language to use\n#language_code = EN # CHANGE CODE HERE, FOR STEP 10 IN THE INSTRUCTIONS\nlanguage_code = SV # CHANGE CODE HERE, FOR STEP 10 IN THE INSTRUCTIONS\n\n# Do the XML-parsing\ntbx_filename = \"/kaggle/input/terms-from-the-swedish-authority-terminology-group/authority_term_list.tbx\"\njson_filename = language_code + \"-term-entries.json\"\nparse_tbx_file_for_language(tbx_filename, json_filename, language_code)\n\n\n# Read the saved output from the json file\n# CHANGE CODE HERE, FOR STEP 6 IN THE INSTRUCTIONS. \n# DONT' CREATE AN EMPTY DICTIONARY, BUT LOAD DATA FROM FILE INSTEAD\nlanguage_dict = {} # Load the json that you have saved to file here\nwith open(json_filename) as fp:\n    language_dict = json.load(fp)\n#print(language_dict)\n    \nletter_count_terms = count_letters_for_entry_type(language_dict, language_code, TERMS)\nprint(language_code,\"Nr of letters for terms:\", letter_count_terms)\nletter_count_definitions = count_letters_for_entry_type(language_dict, language_code, DEFINITIONS)\nprint(language_code, \"Nr of letters for definitions:\", letter_count_definitions)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T21:54:10.585959Z","iopub.execute_input":"2024-09-12T21:54:10.586367Z","iopub.status.idle":"2024-09-12T21:54:10.608114Z","shell.execute_reply.started":"2024-09-12T21:54:10.586329Z","shell.execute_reply":"2024-09-12T21:54:10.607050Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"<Element 'martifHeader' at 0x7d554327d4e0>\n\nFound 24 term entries for the language: sv\n\nFirst and second term entries look like this: [{'terms': ['aktivitetsrapport'], 'definitions': ['redovisning av aktiviteter som utförts under en viss tidsperiod']}, {'terms': ['aktivitetsrapportera'], 'definitions': ['(Arbetsförmedlingen:) redovisa genomförda eller planerade aktiviteter som bidrar till att man får ett arbete eller börjar studera']}]\n\nsv Nr of letters for terms: Counter({'a': 36, 't': 36, 'n': 34, 'e': 30, 's': 28, 'i': 27, 'r': 27, 'k': 20, 'd': 17, 'l': 15, 'o': 14, 'm': 13, 'g': 11, 'ä': 10, ' ': 7, 'p': 6, 'å': 6, 'y': 6, 'h': 6, 'v': 5, 'ö': 3, 'u': 3, 'b': 2, 'c': 2, '-': 1, 'j': 1})\n\nFound 24 term entries for the language: sv\n\nFirst and second term entries look like this: [{'terms': ['aktivitetsrapport'], 'definitions': ['redovisning av aktiviteter som utförts under en viss tidsperiod']}, {'terms': ['aktivitetsrapportera'], 'definitions': ['(Arbetsförmedlingen:) redovisa genomförda eller planerade aktiviteter som bidrar till att man får ett arbete eller börjar studera']}]\n\nsv Nr of letters for definitions: Counter({' ': 199, 'e': 146, 't': 121, 'a': 120, 'r': 116, 'n': 103, 's': 90, 'i': 89, 'l': 66, 'o': 62, 'm': 58, 'd': 53, 'g': 50, 'v': 45, 'k': 45, 'f': 31, 'h': 27, 'ö': 24, 'ä': 22, 'b': 21, 'å': 18, 'u': 14, 'p': 13, 'y': 11, 'c': 10, 'j': 9, '(': 4, ')': 4, ',': 4, ':': 3})\n","output_type":"stream"}]},{"cell_type":"markdown","source":"II. Parsing the Swedish part of the term entry\n-----------------------------------------------\n\n10) CHANGE THE CODE: so that it extracts the Swedish part of the term entry instead. Run it to produce a new json file. (There is already the constant `SV`, that you can use.) Is it the same letters that are most common among the Swedish terms?\n\n11) CHANGE THE CODE: so that is also extracts the Swedish *definitions* for the term entry, i.e., the content that match: `<descrip type=\"definition\">`. It should be possible to have several  definitions for a language in a term entry (although there are no examples of where there are several different definitions in this particular tbx-file). \n\nYou can mirror the code for extracting and saving terms for solving this task. There is a code line that is commented out, that you can use: \n\nThe resulting json file should have the following format when extracting the definitions: \n```\n{\n    \"terms\": [\n            \"aktivitetsrapport\"\n            ],\n    \"definitions\": [\n                \"redovisning av aktiviteter som utf\\u00f6rts under en viss tidsperiod\"\n            ]\n}\n```\n\n**12. In the *Swedish definitions*: How many 'm':s are there and how many 's:'?. Note it down to be able to answer the quizz.**\n> __Answer__: m's: 13, s's: 28","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Extra\n-------\n1) There are many other ways by which you can parse XML using Python. For instance with XPath. Rewrite the code above, so that is does the same, but using [XPath](https://docs.python.org/3/library/xml.etree.elementtree.html#elementtree-xpath)\n\n2) There are many way in which a list can flattened. Rewrite the loop above with another method to [flatten lists](https://realpython.com/python-flatten-list/)\n    \n3) Rewrite this part, so that it is handled by catching an exceptions instead.\n```\n    if language not in terms_dict:\n        return None\n    terms_entries_for_lang = terms_dict[language] \n   \n```","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}